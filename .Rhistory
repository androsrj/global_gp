beta.prior = beta.prior,
beta.Norm = beta.Norm,
x.names = x.names,
run.time = run.time,
K.diag = K.diag,
svc.cols = svc.cols,
dropped.obs = dropped.obs)
class(svc.obj) <- "spSVC"
coefs <- spRecover(svc.obj, start=floor(0.5*n.samples), thin=2,
n.omp.threads=4, verbose=FALSE)
coefs$p.beta.recover.samples
colMeans(coefs$p.beta.recover.samples)
dim(coefs$p.w.recover.samples)
beta.est <- colMeans(coefs$p.beta.recover.samples)
beta.est[2] + rowMeans(coefs$p.w.recover.samples)[101:200]
train$B[,2]
beta.est
beta.est[1] + rowMeans(coefs$p.w.recover.samples)[1:100]
train$B[,1]
setwd("~/research/election2024/scen3")
library(combinat)
library(tidyverse)
library(plotrix)
library(RColorBrewer)
library(mvtnorm)
library(stringr)
library(dplyr)
conditionalProb <- function(state, win, candidate) {
opponent <- ifelse(candidate == "Trump", "Harris", "Trump")
if (win == TRUE) {
num <- sum(outcomes$Prob[outcomes[ , state] == candidate & outcomes$Winner == candidate])
} else {
num <- sum(outcomes$Prob[outcomes[ , state] == opponent & outcomes$Winner == candidate])
}
den <- sum(outcomes$Prob[outcomes[ , state] == candidate])
return(num/den)
}
conditionalProbMulti <- function(states, win, candidate) {
opponent <- ifelse(candidate == "Trump", "Harris", "Trump")
if (win == TRUE) {
num <- sum(outcomes$Prob[outcomes[ , states[1]] == candidate & outcomes[ , states[2]] == candidate & outcomes$Winner == candidate])
} else {
num <- sum(outcomes$Prob[outcomes[ , states[1]] == opponent & outcomes[ , states[2]] == opponent & outcomes$Winner == candidate])
}
den <- sum(outcomes$Prob[outcomes[ , states[1]] == candidate & outcomes[ , states[2]] == candidate])
return(num/den)
}
use.2024 <- TRUE
margins <- data.frame(
az = c(8.5, 10.1, 3.5, -0.4, 1.7),
ga = c(5.2, 8.0, 5.1, -0.3, 1.2),
mi = c(-16.8, -9.5, 0.3, -2.8, -1.8),
nv = c(-12.5, -6.6, -2.4, -2.4, 0.6),
nc = c(-0.3, 2.2, 3.6, 1.3, 1.3),
pa = c(-10.3, -5.2, 0.7, -1.2, 0.0),
wi = c(-13.9, -6.7, 0.7, -0.6, -1.1)
)
if (use.2024 == FALSE) {
margins <- margins[-5, ]
rownames(margins) <- seq(2008, 2020, by = 4)
} else {
rownames(margins) <- seq(2008, 2024, by = 4)
}
round(cor(margins), 2)
round(cov(margins), 2)
# Shrink the correlation matrix towards tighter correlations
lambda <- 0.6
cor.matrix <- cor(margins)
target <- matrix(0.8, 7, 7)
diag(target) <- 1
shrunk.cor <- lambda * target + (1 - lambda) * cor.matrix
shrunk.cor
st.devs <- diag(apply(margins, 2, sd))
Sigma <- st.devs %*% shrunk.cor %*% st.devs
mu <- rep(0, 7)
nReps <- 100000
sim <- rmvnorm(n = nReps, mean = mu, sigma = Sigma)
wins <- sim > 0
outcomes.text <- apply(wins, 1, paste0, collapse = "")
props <- table(outcomes.text) / nReps
combos <- names(props)
length(props)
sort(props)
states <- c("az", "ga", "mi", "nv", "nc", "pa", "wi")
outcomes <- t(sapply(1:length(props), function(i) {
as.logical(str_extract_all(combos[i], "TRUE|FALSE")[[1]])
}))
dim(outcomes)
colnames(outcomes) <- states
outcomes[outcomes == TRUE] <- "Trump"
outcomes[outcomes == FALSE] <- "Harris"
outcomes <- as.data.frame(outcomes)
outcomes$Prob <- as.numeric(unname(props))
outcomes <- outcomes %>% arrange(Prob)
head(outcomes)
tail(outcomes)
evs <- c(11, 16, 15, 6, 16, 19, 10)
trump.start <- 219
harris.start <- 226
outcomes$Winner <- numeric(nrow(outcomes))
for (i in 1:nrow(outcomes)) {
trump.ev <- trump.start + sum(evs * (outcomes[i, 1:7] == "Trump"))
harris.ev <- harris.start + sum(evs * (outcomes[i, 1:7] == "Harris"))
if (trump.ev >= 270) {
outcomes$Winner[i] <- "Trump"
} else if (harris.ev >= 270) {
outcomes$Winner[i] <- "Harris"
} else {
outcomes$Winner[i] <- "Tie"
}
}
table(outcomes$Winner)
aggregate(data = outcomes, Prob ~ Winner, sum)
tail(outcomes)
winner.probs <- aggregate(data = outcomes, Prob ~ Winner, sum)
# Overall win probabilities
p.win.trump <- winner.probs$Prob[3]
p.win.harris <- winner.probs$Prob[1]
p.tie <- winner.probs$Prob[2]
cat(paste0("Trump win probability: ", round(p.win.trump, 3), "\n"))
cat(paste0("Harris win probability: ", round(p.win.harris, 3), "\n"))
cat(paste0("Tie probability: ", round(p.tie, 3), "\n"))
# Conditional win probabilities
L.harris <- c(conditionalProb("az", FALSE, "Harris"),
conditionalProb("ga", FALSE, "Harris"),
conditionalProb("mi", FALSE, "Harris"),
conditionalProb("nc", FALSE, "Harris"),
conditionalProb("nv", FALSE, "Harris"),
conditionalProb("pa", FALSE, "Harris"),
conditionalProb("wi", FALSE, "Harris"))
U.harris <- c(conditionalProb("az", TRUE, "Harris"),
conditionalProb("ga", TRUE, "Harris"),
conditionalProb("mi", TRUE, "Harris"),
conditionalProb("nc", TRUE, "Harris"),
conditionalProb("nv", TRUE, "Harris"),
conditionalProb("pa", TRUE, "Harris"),
conditionalProb("wi", TRUE, "Harris"))
L.trump <- c(conditionalProb("az", FALSE, "Trump"),
conditionalProb("ga", FALSE, "Trump"),
conditionalProb("mi", FALSE, "Trump"),
conditionalProb("nc", FALSE, "Trump"),
conditionalProb("nv", FALSE, "Trump"),
conditionalProb("pa", FALSE, "Trump"),
conditionalProb("wi", FALSE, "Trump"))
U.trump <- c(conditionalProb("az", TRUE, "Trump"),
conditionalProb("ga", TRUE, "Trump"),
conditionalProb("mi", TRUE, "Trump"),
conditionalProb("nc", TRUE, "Trump"),
conditionalProb("nv", TRUE, "Trump"),
conditionalProb("pa", TRUE, "Trump"),
conditionalProb("wi", TRUE, "Trump"))
# WPD plots
jpeg("wp_bands_scen3.jpg", width = 1000, height = 600)
par(mar=c(5, 5, 2, 2), cex = 2)
x <- seq(2, 20, by = 3)
y.harris <- rep(p.win.harris, 7)
plotCI(x, y.harris, ui = U.harris, li = L.harris,
xlim = c(1,22), ylim = c(0.0, 1.0),
col = "blue", xaxt = 'n', lwd = 2 ,
xlab = "Correlated Scenario (3)",
ylab = "Win Probability",
cex.lab = 1.25)
abline(h = p.win.harris, lty = 2, lwd = 2, col = "blue")
abline(h = p.win.trump, lty = 2, lwd = 2, col = "brown3")
x <- seq(3, 21, by = 3)
y.trump <- rep(p.win.trump, 7)
plotCI(x, y.trump, ui = U.trump, li = L.trump,
add = T, xaxt = 'n', lwd = 2,
col = "brown3", xlab = "", ylab = "")
axis(1, at = seq(2.5, 20.5, by = 3),
labels = c("AZ", "GA", "MI", "NC", "NV", "PA", "WI"))
legend("topleft", legend=c("Harris", "Trump"), fill = c("dodgerblue", "brown3"))
dev.off()
wpd <- rbind(U.harris - L.harris, U.trump - L.trump)
rownames(wpd) <- c("Harris", "Trump")
colnames(wpd) <- c("AZ", "GA", "MI", "NC", "NV", "PA", "WI")
wpd <- wpd[ , order(-colSums(wpd))]
jpeg("wp_bar_scen3.jpg", width = 1000, height = 600)
par(mar=c(5, 6, 2, 2), cex = 2)
barplot(wpd,
col = c("dodgerblue", "brown3"),
legend = rownames(wpd),
xlab = "Correlated Scenario (3)",
ylab = "Win Probability Difference (WPD)",
yaxt = 'n',
cex.lab = 1.25,
beside = TRUE)
axis(2, at = seq(0, 1.0, by=0.2), labels = paste0(seq(0, 100, by=20), "%"), las=2)
dev.off()
## Condition on two states at once
# Harris
state.duos <- t(combn(states, 2))
harris.duo.probs <- sapply(1:nrow(state.duos), function(x) {
conditionalProbMulti(states = state.duos[x, ], win = TRUE, candidate = "Harris")
})
duo.harris <- data.frame(state1 = state.duos[,1],
state2 = state.duos[,2],
win.prob.harris = harris.duo.probs) %>%
arrange(-win.prob.harris)
duo.harris
jpeg("duo_harris_scen3.jpg", width = 1000, height = 600)
par(mar=c(7, 7, 4, 2), cex = 2)
barplot(duo.harris$win.prob.harris,
xlab = "", ylab = "",
cex.main = 1.25,
ylim = c(0, 1),
yaxt = 'n',
main = "Harris",
col = terrain.colors(21))
abline(h = p.win.harris, lty = 2)
axis(2, at = seq(0, 1, by=0.2), labels = paste0(seq(0, 100, by=20), "%"), las = 2)
axis(1, at = seq(0.8, 24.75, length=21), labels = paste0(toupper(duo.harris$state1), ", ",
toupper(duo.harris$state2)), las = 2)
title(xlab = "Correlated Scenario (3)",
ylab = "Conditional Win Probability",
cex.lab = 1.4, line = 5)
dev.off()
# Trump
trump.duo.probs <- sapply(1:nrow(state.duos), function(x) {
conditionalProbMulti(states = state.duos[x, ], win = TRUE, candidate = "Trump")
})
duo.trump <- data.frame(state1 = state.duos[,1],
state2 = state.duos[,2],
win.prob.trump = trump.duo.probs) %>%
arrange(-win.prob.trump)
duo.trump
jpeg("duo_trump_scen3.jpg", width = 1000, height = 600)
par(mar=c(7, 7, 4, 2), cex = 2)
barplot(duo.trump$win.prob.trump,
xlab = "", ylab = "",
cex.main = 1.25,
ylim = c(0, 1),
yaxt = 'n',
main = "Trump",
col = terrain.colors(21))
abline(h = p.win.trump, lty = 2)
axis(2, at = seq(0, 1, by=0.2), labels = paste0(seq(0, 100, by=20), "%"), las = 2)
axis(1, at = seq(0.8, 24.75, length=21), labels = paste0(toupper(duo.trump$state1), ", ",
toupper(duo.trump$state2)), las = 2)
title(xlab = "Correlated Scenario (3)",
ylab = "Conditional Win Probability",
cex.lab = 1.4, line = 5)
dev.off()
setwd("~/")
setwd("~/research/global_gp")
library(spBayes)
library(coda)
obj <- readRDS("objects/small_scen1.RDS")
n <- 100
p.theta.samples <- as.mcmc(cbind(t(obj[[1]]$paramSamples$sigb2),
obj[[1]]$paramSamples$tau2,
t(obj[[1]]$paramSamples$thb)))
library(spBayes)
source("other_functions/helper_functions.R")
# Scenario 1
train <- readRDS("data/small/scen1/train.RDS")
test <- readRDS("data/small/scen1/test.RDS")
scen=1
d.max <- max(iDist(train$U))
r <- 2
n <- nrow(train$X)
nTest <- nrow(test$X)
priors <- list("phi.Unif"=list(rep(3/(0.75*d.max), r), rep(3/(0.001*d.max), r)),
"sigma.sq.IG"=list(rep(2, r), rep(1, r)),
"tau.sq.IG"=c(2, 1))
starting <- list("phi"=rep(3/(0.1*d.max), r), "sigma.sq"=rep(1, r), "tau.sq"=1)
tuning <- list("phi"=rep(0.1, r), "sigma.sq"=rep(0.05, r), "tau.sq"=0.1)
n.samples <- 5000
m.3 <- spSVC(train$Y[1:nrow(train$X),] ~ train$X, coords=train$U,
starting=starting, svc.cols=c(1,2),
tuning=tuning, priors=priors, cov.model="exponential",
n.samples=n.samples, n.report=5000, n.omp.threads=4)
m.3$p.theta.samples
head(m.3$p.theta.samples)
mean(m.3$p.theta.samples[,3])
hist(m.3$p.theta.samples[,3])
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
library(MBA)
library(splines)
library(fields)
library(parallel)
library(doParallel)
library(foreach)
nReps <- nCores <- 10
set.seed(999)
which.scens <- 1
##### SCENARIO 1 #####
scen <- 1
dir <- paste0("data/small/scen", scen, "/")
train <- readRDS(paste0(dir, "train.RDS"))
test <- readRDS(paste0(dir, "test.RDS"))
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X; XTest <- test$X
Z <- train$Z; ZTest <- test$Z
Y <- train$Y; YTest <- test$Y
U <- train$U; UTest <- test$U
D <- train$D; DTest <- test$D
K <- 9
q <- ncol(X) + 1
propSD <- list(sigma2 = seq(0.2, 0.4, length = K),
theta = seq(0.7, 0.9, length = K),
sigb2 = seq(0.4, 0.6, length = q),
thb = seq(1.5, 2, length = q),
tau2 = 0.25)
starting <- list(sigma2 = rep(5, K),
theta = rep(.25, K),
sigb2 = rep(0.5, q),
thb = rep(0.2, q),
tau2 = 0.1,
beta = rep(0, 3))
obj <- readRDS("objects/small_scen1.RDS")
length(obj)
obj <- readRDS("objects/small_scen1.RDS")[[1]]
obj <- readRDS("objects/small_scen1.RDS")[[1]]
scen <- 1
dir <- paste0("data/small/scen", scen, "/")
train <- readRDS(paste0(dir, "train.RDS"))
test <- readRDS(paste0(dir, "test.RDS"))
train$h
# Estimate h
sigma2 <- obj$paramSamples$sigma2
theta <- obj$paramSamples$theta
dim(theta)
n.iter <- ncol(obj$paramSamples$sigma2)
dim(sigma2)
source("other_functions/bsplines_2_3D.R")
S <- nrow(train$Z)
S
i=1
sigma2 <- obj$paramSamples$sigma2[ , i]
theta <- obj$paramSamples$theta[ , i]
BF <- Bsplines_2D(Z, df = c(sqrt(K), sqrt(K)))
Z <- train$Z
BF <- Bsplines_2D(Z, df = c(sqrt(K), sqrt(K)))
K <- 9
S <- nrow(train$Z)
sigma2 <- obj$paramSamples$sigma2[ , i]
theta <- obj$paramSamples$theta[ , i]
BF <- Bsplines_2D(Z, df = c(sqrt(K), sqrt(K)))
basis <- lapply(1:K, function(k) {
Reduce("rbind", lapply(1:S, \(s) BF[s, k] * diag(n)))
})
BF
class(BF)
dim(BF)
library(Matrix)
i
sigma2 <- obj$paramSamples$sigma2[ , i]
theta <- obj$paramSamples$theta[ , i]
BF <- Bsplines_2D(Z, df = c(sqrt(K), sqrt(K)))
basis <- lapply(1:K, function(k) {
Reduce("rbind", lapply(1:S, \(s) BF[s, k] * diag(n)))
})
eta <- matrix(0, nrow = n, ncol = K)
BF <- Bsplines_2D(Z, df = c(sqrt(K), sqrt(K)))
C <- lapply(1:K, function(k) {
sigma2[k] * exp(-theta[k] * D)
})
theta
C <- lapply(1:K, function(k) {
sigma2[k] * exp(-theta[k] * D)
})
k=1
sigma2[k] * exp(-theta[k] * D)
-theta[1]
D
# Distance matrix
D <- fields::rdist(train$U)
C <- lapply(1:K, function(k) {
sigma2[k] * exp(-theta[k] * D)
})
C.array <- simplify2array(C)  # array of dim n x n x K
C.array <- aperm(C.array, c(3, 1, 2))  # now K x n x n
W.list <- lapply(1:K, function(k) tcrossprod(BF[, k]))  # each S x S
W.array <- simplify2array(W.list)  # S x S x K
C.eta <- Reduce('+', lapply(1:K, function(k) kronecker(W.array[, , k], C.array[k, , ])))
dim(C.eta)
eta <- rmvnorm(1, Sigma = C.eta)
eta <- rmvnorm(1, Sigma = C.eta + 0.001*diag(1000))
eta <- rmvnorm(1, Sigma = C.eta + 0.0001*diag(1000))
eta <- rmvnorm(1, Sigma = C.eta + 0.00001*diag(1000))
library(mvtnorm)
eta <- rmvnorm(1, sigma = C.eta)
eta <- mvtnorm::rmvnorm(1, sigma = C.eta)
eta
dim(eta)
library(Matrix)
library(fields)
library(mvtnorm)
source("other_functions/bsplines_2_3D.R")
obj <- readRDS("objects/small_scen1.RDS")[[1]]
scen <- 1
dir <- paste0("data/small/scen", scen, "/")
train <- readRDS(paste0(dir, "train.RDS"))
test <- readRDS(paste0(dir, "test.RDS"))
n.iter <- ncol(obj$paramSamples$sigma2)
K <- 9
# Response variable, Y
Y <- train$Y
n <- nrow(Y)
Z <- train$Z
S <- nrow(Z)
# Distance matrix
D <- fields::rdist(train$U)
# Sample eta and calculate h
h <- matrix(0, nrow = nrow(Y)*S, ncol = n.iter)
for (i in 1:n.iter) {
sigma2 <- obj$paramSamples$sigma2[ , i]
theta <- obj$paramSamples$theta[ , i]
BF <- Bsplines_2D(Z, df = c(sqrt(K), sqrt(K)))
#basis <- lapply(1:K, function(k) {
#  Reduce("rbind", lapply(1:S, \(s) BF[s, k] * diag(n)))
#})
#eta <- matrix(0, nrow = n, ncol = K)
C <- lapply(1:K, function(k) {
sigma2[k] * exp(-theta[k] * D)
})
C.array <- simplify2array(C)  # array of dim n x n x K
C.array <- aperm(C.array, c(3, 1, 2))  # now K x n x n
W.list <- lapply(1:K, function(k) tcrossprod(BF[, k]))  # each S x S
W.array <- simplify2array(W.list)  # S x S x K
C.eta <- Reduce('+', lapply(1:K, function(k) kronecker(W.array[, , k], C.array[k, , ])))
h[ , i] <- c(mvtnorm::rmvnorm(1, sigma = C.eta))
}
mat <- matrix(c(rep(1:10, each = 100), rep(1:100, times = 10)), ncol = 2)
mat
dim(mat)
head(mat)
new.order <- order(mat[, 2], mat[, 1])
new.order
dim(mat)
P <- diag(n*S)[new.order, ]
P
dim(P)
P[1:5,1:5]
P[1:25,1:25]
dim(train$X)
?tcrossprod
dim(P)
p <- ncol(train$X)
p
# Predictors (local and global)
X <- cbind(rep(1, n), train$X)
p <- ncol(X)
n
# Response variable, Y
Y <- train$Y
n <- 100
# Predictors (local and global)
X <- cbind(rep(1, n), train$X)
p <- ncol(X)
Z <- train$Z
S <- nrow(Z)
s=1
ind <- ((s-1)*n+1):(s*n)
ind
s=3
((s-1)*n+1):(s*n)
# Diagonal version of X
X2 <- matrix(0, n, n * p)
for (i in seq_len(n)) {
cols <- ((i - 1) * p + 1):(i * p)  # slot for this row
X2[i, cols] <- X[i, ]
}
dim(X2)
X2[1:10, 1:10]
# Permutation matrix
mat <- matrix(c(rep(1:p, each = n), rep(1:n, times = p)), ncol = 2)
head(mat)
# Permutation matrix
mat <- matrix(c(rep(1:p, each = n), rep(1:n, times = p)), ncol = 2)
new.order <- order(mat[, 2], mat[, 1])
P <- diag(n*S)[new.order, ]
dim(P)
dim(X2)
crossprod(1:3)
big.b <- crossprod(X2 %*% P)
dim(big.b)
big.b[1:5,1:5]
sum(big.b > 0 & big.b < 1)
dim(X2)
dim(P)
mat
dim(mat)
dim(P)
t(P) %*% mat
# Permutation matrix
mat <- matrix(c(rep(1:p, each = n), rep(1:n, times = p)), ncol = 2)
new.order <- order(mat[, 2], mat[, 1])
P <- diag(n*p)[new.order, ]
dim(P)
big.b <- crossprod(X2 %*% P)
dim(big.b)
dim(obj$paramSamples$sigb2)
Sigma.p.inv <- lapply(1:p, \(j) solve(sigb2[j] * exp(-thb[j] * D)))
sigb2 <- obj$paramSamples$sigb2[ , i]
thb <- obj$paramSamples$thb[ , i]
Sigma.p.inv <- lapply(1:p, \(j) solve(sigb2[j] * exp(-thb[j] * D)))
Sigma.inv <- as.matrix(bdiag(Sigma.p.inv))
dim(Sigma.inv)
big.b <- crossprod(X2 %*% P) / tau2 + Sigma.inv
tau2 <- obj$paramSamples$tau2[i]
big.b <- crossprod(X2 %*% P) / tau2 + Sigma.inv
dim(big.b)
