D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(1.5, 2.9, length = K),
tau2 = 0.2)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(1.5, 2.9, length = K),
tau2 = 0.2)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(1.5, 2.9, length = K),
tau2 = 0.2)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(1.5, 2.9, length = K),
tau2 = 0.2)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(1.5, 2.9, length = K),
tau2 = 0.2)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(0.3, 0.7, length = K),
tau2 = 0.8)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(0.3, 0.7, length = K),
tau2 = 0.8)
theta = runif(9, 0.5, 3)
# Dimensions
S <<- nrow(X)
n <<- length(Y) / S
subjs <<- 1:S
STest <<- nrow(XTest)
nTest <<- length(YTest) / STest
J <<- matrix(1, nrow = n * S, ncol = 1)
K <<- K
theta <<- theta
BF <- Bsplines_2D(X, df = c(sqrt(K), sqrt(K)))
basis <<- lapply(1:K, function(k) {
Reduce("rbind", lapply(1:S, \(s) BF[s, k] * diag(n)))
})
BFTest <- Bsplines_2D(XTest, df = c(sqrt(K), sqrt(K)))
basisTest <<- lapply(1:K, function(k) {
Reduce("rbind", lapply(1:STest, \(s) BFTest[s, k] * diag(nTest)))
})
# MCMC chain properties
nIter <- nBurn + nIter # 15 to 20 thousand ideally
nIter=100
# Tuning parameters for variance of each proposal distribution
# Can be user-supplied
sdSigma2 <- propSD[[1]]
sdTau2 <- propSD[[2]]
trSigma2 <- matrix(0, nrow = K, ncol = nIter)
trTau2 <- mu <- numeric(nIter) # Transformed parameters
acceptSigma2 <- acceptTau2 <- 0 # Track acceptance rates
# Initial values of transformed parameters (except for mu, not transformed)
trSigma2[, 1] <- log(1:K)
trTau2[1] <- log(0.2)
mu[1] <- 0
# Base of covariance matrix for updating sigma2 and tau2 (only need to compute once)
B <<- baseVariance(theta, D = D)
Sigma <<- Reduce("+", lapply(1:K, \(k) exp(trSigma2[k, 1] * B[[k]]))) + exp(trTau2[1]) * diag(n * S)
# Base of covariance matrix for predictions
BTest <- lapply(1:K, \(k) tcrossprod(basisTest[[k]] %*% exp(-theta[k] * DTest), basisTest[[k]]))
SigmaTest <<- Reduce("+", lapply(1:K, function(k) {
exp(trSigma2[k, 1]) * BTest[[k]]
})) + exp(trTau2[1]) * diag(STest * nTest)
# Initial predictions for test subjects
YPreds <- matrix(data = NA, nrow = nTest * STest, ncol = nIter)
YPreds[ , 1] <- t(rmvnorm(1, mean = rep(mu[1], nTest * STest), sigma = SigmaTest))
# Run Gibbs/Metropolis for one chain
for (i in 2:nIter) {
cat(paste0("Beginning iteration ", i, ".\n"))
### Metropolis update (sigma2) ###
propTrSigma2 <- rnorm(K, mean = trSigma2[ , i - 1], sd = sdSigma2)
MHratio <<- logRatioSigma2(propTrSigma2,
trSigma2[, i - 1],
trTau2[i - 1],
mu[i - 1])
if(runif(1) < exp(MHratio)) {
trSigma2[, i] <- propTrSigma2
Sigma <<- SigmaProp
acceptSigma2 <- acceptSigma2 + 1
} else {
trSigma2[, i] <- trSigma2[, i - 1]
}
cat("Sigma2 updated \n")
### Metropolis update (tau2) ###
propTrTau2 <- rnorm(1, mean = trTau2[i - 1], sd = sdTau2)
MHratio <- logRatioTau2(trSigma2[i - 1],
propTrTau2,
trTau2[i - 1],
mu[i - 1])
if (runif(1) < exp(MHratio)) {
trTau2[i] <- propTrTau2
Sigma <<-  SigmaProp
acceptTau2 <- acceptTau2 + 1
} else {
trTau2[i] <- trTau2[i - 1]
}
cat("Tau2 updated \n")
### Gibbs update (mu) ###
SigmaInv <- solve(Sigma)
SigmaMu <- 1 / crossprod(J, SigmaInv %*% J) + 1
meanMu <- SigmaMu * crossprod(J, SigmaInv %*% Y)
mu[i] <- t(rmvnorm(1, meanMu, SigmaMu))
cat("Mu updated \n")
### Posterior predictive sampling for test subjects ###
SigmaTest <<- Reduce("+", lapply(1:K, function(k) {
exp(trSigma2[k, i]) * BTest[[k]]
})) + exp(trTau2[i]) * diag(STest * nTest)
YPreds[ , i] <- t(rmvnorm(1, mean = rep(mu[i], nTest * STest), sigma = SigmaTest))
}
View(propSD)
View(propSD)
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(0.3, 0.7, length = K),
tau2 = 0.8)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(0.3, 0.7, length = K),
tau2 = 0.8)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
exp(-.528)
exp(-.758)
exP9134
exp(134)
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(0.3, 0.7, length = K),
tau2 = 0.8)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
exp(-0.66)
exp(-0.52)
exp(Inf)
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(0.3, 0.7, length = K),
tau2 = 0.8)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(0.3, 0.7, length = K),
tau2 = 0.8)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
# SOURCES
source("mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
source("other_functions/bsplines_2_3D.R")
load("data/train.RData")
load("data/test.RData")
n <- nrow(train$X)
nTest <- nrow(test$X)
X <- train$X
Y <- train$Y
U <- train$U
D <- train$D
XTest <- test$X
YTest <- test$Y
UTest <- test$U
DTest <- test$D
K <- 9
propSD <- list(sigma2 = seq(0.3, 0.7, length = K),
tau2 = 0.8)
results <- mcmc(X = X, Y = Y, D = D,
K = K,
theta = runif(9, 0.5, 3),
propSD = propSD,
nIter = 200, nBurn = 10, nThin=2,
model = "full_gp")
results$posteriorMeans
results
logRatioTau2 <- function(trSigma2, propTrTau2, prevTrTau2, mu) {
propTau2 <- exp(propTrTau2)
prevTau2 <- exp(prevTrTau2)
SigmaProp <<- Sigma + (propTau2 - prevTau2) * diag(n * S) # B is the base variance from beginning
logLik(SigmaProp, mu) - logLik(Sigma, mu) + # Log Likelihoods
logPriorTau2(propTau2) - logPriorTau2(prevTau2) + # Log Priors
propTrTau2 - prevTrTau2 # Jacobian is exp()
# Taking the log and exp of trTau2 cancels out
}
logRatioTau2(results, -1.42, -0.61, 7.36)
trSigma2=results
propTrTau2=-1.42
prevtrTau2=-0.61
mu=7.36
propTau2 <- exp(propTrTau2)
prevTau2 <- exp(prevTrTau2)
prevTrTau2=-0.61
prevTau2 <- exp(prevTrTau2)
SigmaProp <<- Sigma + (propTau2 - prevTau2) * diag(n * S) # B is the base variance from beginning
SigmaProp
dim(SigmaProp)
hist(SigmaProp)
logLik(SigmaProp, mu) - logLik(Sigma, mu)
logPriorTau2(propTau2) - logPriorTau2(prevTau2)
propTrTau2 - prevTrTau2
logLik(SigmaProp, mu)
logLik(Sigma, mu)
logLik(SigmaProp, mu)
propTau2-prevTau2
logLik(SigmaProp*1.5, mu)
logLik(SigmaProp*100.5, mu)
logLik(SigmaProp*0.5, mu)
logLik(SigmaProp*0.005, mu)
logLik(SigmaProp*1000, mu)
dmvnorm(as.vector(Y), c(mu * J), SigmaProp, log = TRUE)
as.vector(Y)
dmvnorm(as.vector(Y), c(mu * J), SigmaProp, log = TRUE)
mu*J
subjs
sum(sapply(subjs, function(i) {
dmvnorm(as.vector(Y), c(mu * J), Sigma, log = TRUE)
}))
### LOG LIKELIHOOD ###
logLik <- function(Sigma, mu) {
dmvnorm(as.vector(Y), c(mu * J), Sigma, log = TRUE)
}
logLik(SigmaProp, mu)
hist(Sigma)
dim(Sigma)
logLike(diag(500), mu)
logLik(diag(500), mu)
isSymmetric.matrix(SigmaProp)
isSymmetric.matrix(Sigma)
logLik(diag(500)*9, mu)
logLik(diag(500)*900, mu)
logLik(diag(500)*900000, mu)
logLik(diag(500)*90000000000000, mu)
logLik(SigmaProp, mu)
logLik(SigmaProp*0.000000001, mu)
